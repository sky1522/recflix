# ì„ë² ë”© ê¸°ë°˜ ìì—°ì–´ ì˜í™” íƒìƒ‰ â€” ì„¤ê³„ ë¬¸ì„œ

**ì‘ì„±ì¼**: 2026-02-20
**ëª©í‘œ**: "ì˜¤ëŠ˜ ë¹„ì˜¤ëŠ”ë° í˜¼ì ë³´ê¸° ì¢‹ì€ ì”ì”í•œ ì˜í™”" ê°™ì€ ìì—°ì–´ ì¿¼ë¦¬ë¡œ ì˜í™”ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì‹œë§¨í‹± ê²€ìƒ‰ ê¸°ëŠ¥

---

## 1. pgvector ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€

### ì¡°ì‚¬ ê²°ê³¼: **ì‚¬ìš© ë¶ˆê°€**

```sql
-- Railway PostgreSQL 17.7 (Debian 17.7-3.pgdg13+1)
SELECT name FROM pg_available_extensions WHERE name = 'vector';
-- (0 rows)
```

Railway PostgreSQLì—ì„œ pgvector í™•ì¥ì€ ì œê³µë˜ì§€ ì•ŠëŠ”ë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ë ¨ í™•ì¥:
- `pg_trgm` 1.6 (ë¬¸ìì—´ ìœ ì‚¬ë„, ì´ë¯¸ í™œìš© ê°€ëŠ¥)
- `fuzzystrmatch` 1.2 (ìŒì„± ìœ ì‚¬ë„)
- `hstore` 1.8, `unaccent` 1.1

### ëŒ€ì•ˆ ì„ íƒ: **NumPy ì¸ë©”ëª¨ë¦¬ ë²¡í„° ê²€ìƒ‰**

| ëŒ€ì•ˆ | ì¥ì  | ë‹¨ì  | ì í•©ë„ |
|------|------|------|--------|
| **NumPy ì¸ë©”ëª¨ë¦¬** | ì˜ì¡´ì„± 0, 10-20ms ê²€ìƒ‰, ì´ë¯¸ ì„¤ì¹˜ë¨ | ì„œë²„ ì¬ì‹œì‘ ì‹œ ì¬ë¡œë“œ í•„ìš” | **ìµœì ** |
| FAISS | SIMD ìµœì í™”, ëŒ€ê·œëª¨ ì§€ì› | 42Kì— ê³¼ì‰, ì¶”ê°€ ì˜ì¡´ì„± | í–¥í›„ í™•ì¥ ì‹œ |
| ChromaDB | ë©”íƒ€ë°ì´í„° í•„í„°ë§ ë‚´ì¥ | 200-400MB RAM, ì¶”ê°€ ì„œë¹„ìŠ¤ | ê³¼ì‰ |
| Qdrant | í”„ë¡œë•ì…˜ê¸‰ ë²¡í„° DB | ë³„ë„ Railway ì„œë¹„ìŠ¤ í•„ìš” ($5/ì›”) | ê³¼ì‰ |
| Pinecone | ë¬´ë£Œ 10ë§Œ ë²¡í„° | ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ, ì™¸ë¶€ ì˜ì¡´ | ëŒ€ì•ˆ |

**ì„ íƒ ê·¼ê±°**: 42,917í¸ Ã— 1,024ì°¨ì› = **~176MB** â€” NumPyë¡œ ì¶©ë¶„. brute-force ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì´ 10-20msì´ë¯€ë¡œ ì¸ë±ìŠ¤ ë¶ˆí•„ìš”.

---

## 2. ì„ë² ë”© ëª¨ë¸ ì„ íƒ

### ë¹„êµí‘œ

| ëª¨ë¸ | ì°¨ì› | ë¹„ìš© (42,917í¸) | ì¿¼ë¦¬ ë¹„ìš© | í•œêµ­ì–´ í’ˆì§ˆ | ë¡œì»¬/API | Railway ì í•© |
|------|------|----------------|----------|-----------|---------|------------|
| OpenAI text-embedding-3-small | 1,536 | ~$0.06 | ~$0 | ì–‘í˜¸ | API | O |
| jhgan/ko-sroberta-multitask | 768 | $0 | $0 | ìš°ìˆ˜ (í•œêµ­ì–´ ì „ìš©) | ë¡œì»¬ | â–³ (~1.5GB RAM) |
| intfloat/multilingual-e5-large | 1,024 | $0 | $0 | ìš°ìˆ˜ | ë¡œì»¬ | â–³ (~2.1GB RAM) |
| **Voyage AI voyage-multilingual-2** | **1,024** | **$0 (ë¬´ë£Œ 50M í† í°)** | **~$0** | **ìš°ìˆ˜** | **API** | **O** |
| Cohere embed-multilingual-v3.0 | 1,024 | ~$0.30 | ~$0 | ì–‘í˜¸ | API | O |

> Anthropicì€ ì„ë² ë”© APIë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë©°, Voyage AIë¥¼ ê³µì‹ íŒŒíŠ¸ë„ˆë¡œ ê¶Œì¥í•œë‹¤.

### ì„ íƒ: **Voyage AI `voyage-multilingual-2`**

**ì„ íƒ ì´ìœ :**
1. **ë¹„ìš©**: ì²« 50M í† í° ë¬´ë£Œ â†’ 42,917í¸ ì „ì²´ ì„ë² ë”© + ìˆ˜ë…„ê°„ ì¿¼ë¦¬ íŠ¸ë˜í”½ ë¬´ë£Œ
2. **í•œêµ­ì–´ í’ˆì§ˆ**: 27ê°œ ì–¸ì–´ í¬í•¨, í•œêµ­ì–´ ë¦¬íŠ¸ë¦¬ë²Œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ OpenAI/Cohere ëŠ¥ê°€
3. **ì°¨ì›**: 1,024 (176MB ì¸ë©”ëª¨ë¦¬, Railway Hobby ì¶©ë¶„)
4. **Anthropic ê³µì‹ íŒŒíŠ¸ë„ˆ**: Claude ê¸°ë°˜ ì‹œìŠ¤í…œê³¼ ìµœì  í˜¸í™˜
5. **ì»¨í…ìŠ¤íŠ¸**: 32,768 í† í° (ê¸´ overviewë„ ë¬¸ì œì—†ìŒ)
6. **Railway ë©”ëª¨ë¦¬ ë¶€ë‹´ ì—†ìŒ**: API í˜¸ì¶œì´ë¯€ë¡œ ëª¨ë¸ ë¡œë“œ ë¶ˆí•„ìš”

**ë¹„ìš© ì‚°ì¶œ:**
- 42,917í¸ Ã— í‰ê·  214ì(í•œêµ­ì–´) â‰ˆ 42,917 Ã— 70í† í° = ~3.0M í† í°
- ë¬´ë£Œ 50M í† í° ì´ë‚´ â†’ **$0**
- ì¿¼ë¦¬ë‹¹: ~70í† í° â†’ ë¬´ë£Œ í•œë„ ë‚´ì—ì„œ ~71ë§Œ ì¿¼ë¦¬ ê°€ëŠ¥

---

## 3. ì„ë² ë”© ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ì„¤ê³„

### í˜„ì¬ ë°ì´í„° í˜„í™©

| í•„ë“œ | ì»¤ë²„ë¦¬ì§€ | ì˜ˆì‹œ |
|------|---------|------|
| overview (í•œêµ­ì–´) | 42,903/42,917 (99.97%) | "ì´‰ë§ë°›ëŠ” ì€í–‰ ê°„ë¶€ ì•¤ë”” ë“€í”„ë ˆì¸ì€..." |
| emotion_tags (JSONB) | 42,917/42,917 (100%) | `{"deep":0.9, "healing":0.8, ...}` |
| genres | ì—°ê²° í…Œì´ë¸” (19ì¢…) | "ë“œë¼ë§ˆ, ë²”ì£„" |
| keywords | 34,214/42,917 (79.7%), 88ì¢… | "ì‚¬ë‘, ê°€ì¡±, ë¹„ë°€" |
| mbti_scores (JSONB) | 42,917/42,917 (100%) | 16ì¢… ì ìˆ˜ |
| weather_scores (JSONB) | 42,917/42,917 (100%) | 4ì¢… ì ìˆ˜ |
| director_ko | ëŒ€ë¶€ë¶„ ì¡´ì¬ | "í”„ë­í¬ ë‹¤ë¼ë³¸íŠ¸" |
| cast_ko | 100% í•œê¸€ | "íŒ€ ë¡œë¹ˆìŠ¤, ëª¨ê±´ í”„ë¦¬ë¨¼" |

### ì„ë² ë”© í…ìŠ¤íŠ¸ í…œí”Œë¦¿

```python
def build_embedding_text(movie: dict) -> str:
    """ì˜í™” ë°ì´í„°ë¥¼ ì‹œë§¨í‹± ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    parts = []

    # 1. ì œëª© (í•œêµ­ì–´ + ì˜ì–´)
    parts.append(f"ì œëª©: {movie['title_ko']}")
    if movie.get('title') and movie['title'] != movie['title_ko']:
        parts.append(f"ì˜ì–´ ì œëª©: {movie['title']}")

    # 2. ì¥ë¥´
    if movie.get('genres'):
        parts.append(f"ì¥ë¥´: {movie['genres']}")

    # 3. ì¤„ê±°ë¦¬ (í•µì‹¬ ì‹œë§¨í‹± ì •ë³´)
    if movie.get('overview'):
        parts.append(f"ì¤„ê±°ë¦¬: {movie['overview'][:500]}")

    # 4. ê°ì„± íƒœê·¸ (ë†’ì€ ì ìˆ˜ë§Œ ìì—°ì–´ë¡œ ë³€í™˜)
    if movie.get('emotion_tags'):
        emotion_labels = {
            'healing': 'íë§/ì¹˜ìœ ', 'tension': 'ê¸´ì¥/ìŠ¤ë¦´',
            'energy': 'í™œê¸°/ì—ë„ˆì§€', 'romance': 'ë¡œë§¨ìŠ¤/ê°ì„±',
            'deep': 'ê¹Šì€/ì² í•™ì ', 'fantasy': 'íŒíƒ€ì§€/ìƒìƒ',
            'light': 'ê°€ë²¼ìš´/ìœ ì¾Œ'
        }
        high_emotions = [
            emotion_labels[k]
            for k, v in movie['emotion_tags'].items()
            if isinstance(v, (int, float)) and v >= 0.5
        ]
        if high_emotions:
            parts.append(f"ë¶„ìœ„ê¸°: {', '.join(high_emotions)}")

    # 5. ë‚ ì”¨ ì í•©ë„ (ë†’ì€ ì ìˆ˜ë§Œ)
    if movie.get('weather_scores'):
        weather_labels = {
            'sunny': 'ë§‘ì€ ë‚ ', 'rainy': 'ë¹„ ì˜¤ëŠ” ë‚ ',
            'cloudy': 'íë¦° ë‚ ', 'snowy': 'ëˆˆ ì˜¤ëŠ” ë‚ '
        }
        high_weather = [
            weather_labels[k]
            for k, v in movie['weather_scores'].items()
            if isinstance(v, (int, float)) and v >= 0.3
        ]
        if high_weather:
            parts.append(f"ì–´ìš¸ë¦¬ëŠ” ë‚ ì”¨: {', '.join(high_weather)}")

    # 6. MBTI ì í•©ë„ (ìƒìœ„ 3ê°œ)
    if movie.get('mbti_scores'):
        sorted_mbti = sorted(
            movie['mbti_scores'].items(),
            key=lambda x: float(x[1]) if x[1] else 0, reverse=True
        )[:3]
        high_mbti = [k for k, v in sorted_mbti if float(v) >= 0.2]
        if high_mbti:
            parts.append(f"MBTI ì¶”ì²œ: {', '.join(high_mbti)}")

    # 7. í‚¤ì›Œë“œ
    if movie.get('keywords'):
        parts.append(f"í‚¤ì›Œë“œ: {movie['keywords']}")

    # 8. ê°ë…
    if movie.get('director_ko'):
        parts.append(f"ê°ë…: {movie['director_ko']}")

    return '\n'.join(parts)
```

### ì˜ˆì‹œ ì¶œë ¥ (ì‡¼ìƒí¬ íƒˆì¶œ, id=278)

```
ì œëª©: ì‡¼ìƒí¬ íƒˆì¶œ
ì˜ì–´ ì œëª©: The Shawshank Redemption
ì¥ë¥´: ë“œë¼ë§ˆ, ë²”ì£„
ì¤„ê±°ë¦¬: ì´‰ë§ë°›ëŠ” ì€í–‰ ê°„ë¶€ ì•¤ë”” ë“€í”„ë ˆì¸ì€ ì•„ë‚´ì™€ ê·¸ë…€ì˜ ì •ë¶€ë¥¼ ì‚´í•´í–ˆë‹¤ëŠ” ëˆ„ëª…ì„ ì“´ë‹¤. ì£¼ë³€ì˜ ì¦ì–¸ê³¼ ì‚´í•´ í˜„ì¥ì˜ ê·¸ëŸ´ë“¯í•œ ì¦ê±°ë“¤ë¡œ ê·¸ëŠ” ì¢…ì‹ í˜•ì„ ì„ ê³ ë°›ê³  ì•…ì§ˆë²”ë“¤ë§Œ ìˆ˜ìš©í•œë‹¤ëŠ” ì§€ì˜¥ê°™ì€ êµë„ì†Œ ì‡¼ìƒí¬ë¡œ í–¥í•œë‹¤...
ë¶„ìœ„ê¸°: ê¹Šì€/ì² í•™ì , íë§/ì¹˜ìœ , ê¸´ì¥/ìŠ¤ë¦´
ì–´ìš¸ë¦¬ëŠ” ë‚ ì”¨: ë¹„ ì˜¤ëŠ” ë‚ , íë¦° ë‚ 
MBTI ì¶”ì²œ: ENTJ, INTJ, ISTJ
í‚¤ì›Œë“œ: ì •ë¶€
ê°ë…: í”„ë­í¬ ë‹¤ë¼ë³¸íŠ¸
```

ì˜ˆìƒ í…ìŠ¤íŠ¸ ê¸¸ì´: í‰ê·  300-500ì (í•œêµ­ì–´) â†’ ~100-170 í† í°

---

## 4. DB ìŠ¤í‚¤ë§ˆ ë³€ê²½

### pgvector ì—†ì´ ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°©ë²•

pgvectorê°€ ì—†ìœ¼ë¯€ë¡œ ë²¡í„°ë¥¼ DBì— ì €ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ì‹ :

**íŒŒì¼ ê¸°ë°˜ ì €ì¥**: `movie_embeddings.npy` (NumPy ë°”ì´ë„ˆë¦¬)
- í¬ê¸°: 42,917 Ã— 1,024 Ã— 4ë°”ì´íŠ¸ = **~176MB**
- FastAPI ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ì— ë¡œë“œ
- ì˜í™” ID â†’ ì¸ë±ìŠ¤ ë§¤í•‘: `movie_id_index.json`

### ë§ˆì´ê·¸ë ˆì´ì…˜ SQL (ì„ íƒì , ë©”íƒ€ë°ì´í„°ìš©)

```sql
-- ì„ë² ë”© ìƒì„± ì—¬ë¶€ ì¶”ì ìš© ì»¬ëŸ¼ (ì„ íƒì )
ALTER TABLE movies ADD COLUMN IF NOT EXISTS has_embedding BOOLEAN DEFAULT FALSE;
CREATE INDEX IF NOT EXISTS idx_movies_has_embedding ON movies(has_embedding) WHERE has_embedding = FALSE;
```

### íŒŒì¼ êµ¬ì¡°

```
backend/
  data/
    embeddings/
      movie_embeddings.npy       # (42917, 1024) float32, ~176MB
      movie_id_index.json        # {"0": 278, "1": 840464, ...} idxâ†’movie_id
      embedding_metadata.json    # {"model": "voyage-multilingual-2", "dims": 1024, "count": 42917, "created_at": "..."}
```

---

## 5. API ì„¤ê³„

### ì—”ë“œí¬ì¸íŠ¸

```
GET /api/v1/movies/semantic-search?q=ìì—°ì–´ì¿¼ë¦¬&limit=20&age_rating=all
```

### íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|---------|------|------|------|
| q | string | O | ìì—°ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ (ìµœì†Œ 2ì) |
| limit | int | X | ë°˜í™˜ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 20, ìµœëŒ€ 50) |
| age_rating | string | X | ì—°ë ¹ë“±ê¸‰ í•„í„° (all/family/teen/adult) |
| weather | string | X | í˜„ì¬ ë‚ ì”¨ (sunny/rainy/cloudy/snowy) â€” ì¬ë­í‚¹ì— í™œìš© |
| mood | string | X | í˜„ì¬ ê¸°ë¶„ â€” ì¬ë­í‚¹ì— í™œìš© |

### ì²˜ë¦¬ íë¦„

```
ì‚¬ìš©ì ì¿¼ë¦¬ "ë¹„ì˜¤ëŠ” ë‚  í˜¼ì ë³´ê¸° ì¢‹ì€ ì”ì”í•œ ì˜í™”"
    â”‚
    â–¼
[1] Redis ìºì‹œ í™•ì¸ (ìºì‹œ í‚¤: semantic:{query_hash}:{params})
    â”‚ íˆíŠ¸ â†’ ì¦‰ì‹œ ë°˜í™˜
    â”‚ ë¯¸ìŠ¤ â†“
    â–¼
[2] Voyage AI APIë¡œ ì¿¼ë¦¬ ì„ë² ë”© ë³€í™˜ (1,024ì°¨ì›)
    â”‚ ~100-200ms (API í˜¸ì¶œ)
    â”‚
    â–¼
[3] NumPy ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ (Top 100 í›„ë³´)
    â”‚ ~10-20ms (ì¸ë©”ëª¨ë¦¬ brute-force)
    â”‚ corpus_embeddings @ query_embedding â†’ scores
    â”‚ np.argpartitionìœ¼ë¡œ Top 100 ì¶”ì¶œ
    â”‚
    â–¼
[4] DBì—ì„œ í›„ë³´ ì˜í™” ì¡°íšŒ (100í¸)
    â”‚ SELECT * FROM movies WHERE id IN (...)
    â”‚ + genres JOIN
    â”‚
    â–¼
[5] í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ (ê¸°ì¡´ ì—”ì§„ í™œìš©)
    â”‚ semantic_score * 0.6 + hybrid_score * 0.4
    â”‚ hybrid_score = f(weather, mood, mbti, personal)
    â”‚ í’ˆì§ˆ í•„í„°: weighted_score >= 6.0
    â”‚
    â–¼
[6] ìƒìœ„ 20í¸ ë°˜í™˜ + Redis ìºì‹œ ì €ì¥ (TTL 30ë¶„)
```

### ì‘ë‹µ ìŠ¤í‚¤ë§ˆ

```python
class SemanticSearchResult(BaseModel):
    """ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ ì•„ì´í…œ"""
    id: int
    title: str
    title_ko: str | None
    poster_path: str | None
    release_date: str | None
    weighted_score: float | None
    genres: list[str]
    semantic_score: float        # ë²¡í„° ìœ ì‚¬ë„ (0~1)
    relevance_score: float       # ìµœì¢… ì¬ë­í‚¹ ì ìˆ˜ (0~1)
    match_reason: str            # "ì¤„ê±°ë¦¬ ìœ ì‚¬", "ë¶„ìœ„ê¸° ì¼ì¹˜" ë“±

class SemanticSearchResponse(BaseModel):
    """ì‹œë§¨í‹± ê²€ìƒ‰ ì‘ë‹µ"""
    query: str
    results: list[SemanticSearchResult]
    total: int
    search_time_ms: float
```

### ì¿¼ë¦¬ ì„ë² ë”© ìºì‹± ì „ëµ

```python
# Redis ìºì‹œ ê³„ì¸µ:
# 1. ì¿¼ë¦¬ ì„ë² ë”© ìºì‹œ: semantic_emb:{query_hash} â†’ ë²¡í„°(bytes), TTL 24ì‹œê°„
# 2. ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ: semantic_res:{query_hash}:{params_hash} â†’ JSON, TTL 30ë¶„

import hashlib

def get_query_cache_key(query: str) -> str:
    normalized = query.strip().lower()
    query_hash = hashlib.md5(normalized.encode()).hexdigest()[:12]
    return f"semantic_emb:{query_hash}"

def get_result_cache_key(query: str, limit: int, age_rating: str | None) -> str:
    normalized = query.strip().lower()
    params = f"{limit}:{age_rating or 'none'}"
    combined = f"{normalized}:{params}"
    result_hash = hashlib.md5(combined.encode()).hexdigest()[:12]
    return f"semantic_res:{result_hash}"
```

### ì½”ë“œ ì˜ˆì‹œ â€” ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ

```python
# backend/app/api/v1/semantic_search.py

import json
import logging
import time
from pathlib import Path

import numpy as np
from fastapi import APIRouter, Depends, Query, Request
from sqlalchemy.orm import Session, selectinload

from app.core.deps import get_db
from app.core.rate_limit import limiter
from app.models import Movie
from app.services.llm import get_redis_client

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/movies", tags=["Movies"])

# --- ì¸ë©”ëª¨ë¦¬ ë²¡í„° ì¸ë±ìŠ¤ ---
_corpus_embeddings: np.ndarray | None = None  # (N, 1024), L2 normalized
_movie_ids: list[int] = []                     # index â†’ movie_id ë§¤í•‘

EMBEDDINGS_DIR = Path(__file__).parent.parent.parent.parent / "data" / "embeddings"


def load_embeddings() -> None:
    """ì„œë²„ ì‹œì‘ ì‹œ ì„ë² ë”©ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
    global _corpus_embeddings, _movie_ids

    emb_path = EMBEDDINGS_DIR / "movie_embeddings.npy"
    idx_path = EMBEDDINGS_DIR / "movie_id_index.json"

    if not emb_path.exists():
        logger.warning("Embedding file not found: %s", emb_path)
        return

    _corpus_embeddings = np.load(str(emb_path)).astype(np.float32)
    # L2 ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ â†’ ë‚´ì ìœ¼ë¡œ ë³€í™˜)
    norms = np.linalg.norm(_corpus_embeddings, axis=1, keepdims=True)
    norms[norms == 0] = 1  # 0ë²¡í„° ë°©ì§€
    _corpus_embeddings = _corpus_embeddings / norms

    with open(idx_path, "r") as f:
        idx_map = json.load(f)
    _movie_ids = [idx_map[str(i)] for i in range(len(idx_map))]

    logger.info(
        "Loaded %d movie embeddings (%d dims, %.1f MB)",
        len(_movie_ids), _corpus_embeddings.shape[1],
        _corpus_embeddings.nbytes / 1024 / 1024
    )


def search_similar(query_embedding: np.ndarray, top_k: int = 100) -> list[tuple[int, float]]:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ Top-K ê²€ìƒ‰. (movie_id, score) ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    if _corpus_embeddings is None:
        return []

    query_norm = query_embedding / np.linalg.norm(query_embedding)
    scores = _corpus_embeddings @ query_norm  # (N,)

    # Top-K ì¶”ì¶œ (argpartitionì€ O(N)ìœ¼ë¡œ argsort O(N log N)ë³´ë‹¤ ë¹ ë¦„)
    if top_k < len(scores):
        top_indices = np.argpartition(scores, -top_k)[-top_k:]
        top_indices = top_indices[np.argsort(scores[top_indices])[::-1]]
    else:
        top_indices = np.argsort(scores)[::-1][:top_k]

    return [(int(_movie_ids[i]), float(scores[i])) for i in top_indices]


def is_semantic_search_available() -> bool:
    """ì‹œë§¨í‹± ê²€ìƒ‰ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    return _corpus_embeddings is not None and len(_movie_ids) > 0
```

### ì½”ë“œ ì˜ˆì‹œ â€” Voyage AI ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸

```python
# backend/app/services/embedding.py

import logging
from functools import lru_cache

import httpx
import numpy as np

from app.core.config import settings
from app.services.llm import get_redis_client

logger = logging.getLogger(__name__)

VOYAGE_API_URL = "https://api.voyageai.com/v1/embeddings"
VOYAGE_MODEL = "voyage-multilingual-2"
EMBEDDING_DIM = 1024
CACHE_TTL = 86400  # 24ì‹œê°„


async def get_query_embedding(text: str) -> np.ndarray | None:
    """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ Voyage AIë¡œ ì„ë² ë”© ë³€í™˜. Redis ìºì‹± ì ìš©."""
    import hashlib

    cache_key = f"semantic_emb:{hashlib.md5(text.strip().lower().encode()).hexdigest()[:12]}"

    # Redis ìºì‹œ í™•ì¸
    redis = await get_redis_client()
    if redis:
        try:
            cached = await redis.get(cache_key)
            if cached:
                return np.frombuffer(cached, dtype=np.float32)
        except Exception:
            pass

    # Voyage AI API í˜¸ì¶œ
    api_key = settings.VOYAGE_API_KEY
    if not api_key:
        logger.error("VOYAGE_API_KEY not set")
        return None

    async with httpx.AsyncClient(timeout=10.0) as client:
        response = await client.post(
            VOYAGE_API_URL,
            json={
                "input": [text],
                "model": VOYAGE_MODEL,
                "input_type": "query",
            },
            headers={"Authorization": f"Bearer {api_key}"},
        )
        response.raise_for_status()
        data = response.json()

    embedding = np.array(data["data"][0]["embedding"], dtype=np.float32)

    # Redis ìºì‹œ ì €ì¥
    if redis:
        try:
            await redis.setex(cache_key, CACHE_TTL, embedding.tobytes())
        except Exception:
            pass

    return embedding
```

---

## 6. í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½

### ë°©ì•ˆ: ê¸°ì¡´ SearchAutocompleteì— ì‹œë§¨í‹± ê²€ìƒ‰ í†µí•©

ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ **ê³µì¡´**í•˜ëŠ” ë°©ì‹. ì‚¬ìš©ì ê²½í—˜ ë³€ê²½ ìµœì†Œí™”.

### ë³€ê²½ ì‚¬í•­

#### 6-1. ê²€ìƒ‰ ëª¨ë“œ ìë™ ê°ì§€

```typescript
// lib/searchUtils.ts

/** ìì—°ì–´ ì¿¼ë¦¬ì¸ì§€ íŒë³„ (ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±) */
export function isNaturalLanguageQuery(query: string): boolean {
  // 2ë‹¨ì–´ ì´í•˜ â†’ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì˜í™” ì œëª©, ë°°ìš° ì´ë¦„)
  const words = query.trim().split(/\s+/);
  if (words.length <= 2) return false;

  // ìì—°ì–´ íŒ¨í„´ ê°ì§€
  const nlPatterns = [
    /ì¢‹ì€|ì–´ìš¸ë¦¬ëŠ”|ë³¼ë§Œí•œ|ì¶”ì²œ/,     // ì¶”ì²œ ìš”ì²­
    /ê¸°ë¶„|ë¶„ìœ„ê¸°|ëŠë‚Œ|ê°ì„±/,         // ê°ì„± í‘œí˜„
    /ë‚ ì”¨|ë¹„|ëˆˆ|ë§‘ì€|íë¦°/,          // ë‚ ì”¨ ê´€ë ¨
    /í˜¼ì|ê°™ì´|ì—°ì¸|ê°€ì¡±|ì¹œêµ¬/,       // ìƒí™© í‘œí˜„
    /ì”ì”í•œ|ê¸´ì¥ê°|ë¬´ì„œìš´|ì¬ë°ŒëŠ”|ìŠ¬í”ˆ/, // í˜•ìš©ì‚¬
    /ì‹¶|ë•Œ|ë‚ /,                      // ì„œìˆ  íŒ¨í„´
  ];

  return nlPatterns.some(p => p.test(query));
}
```

#### 6-2. SearchAutocomplete ìˆ˜ì •

```diff
 // components/search/SearchAutocomplete.tsx

+ import { isNaturalLanguageQuery } from "@/lib/searchUtils";
+ import { semanticSearch, type SemanticSearchResult } from "@/lib/api";

  // ìì—°ì–´ ê°ì§€ ì‹œ ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ë„ í‘œì‹œ
  useEffect(() => {
    const fetchResults = async () => {
+     // ìì—°ì–´ ì¿¼ë¦¬ â†’ ì‹œë§¨í‹± ê²€ìƒ‰
+     if (isNaturalLanguageQuery(debouncedQuery)) {
+       setIsSemanticMode(true);
+       const semanticResults = await semanticSearch(debouncedQuery, 8);
+       setSemanticResults(semanticResults);
+     } else {
+       setIsSemanticMode(false);
+     }

      // ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ (í•­ìƒ ì‹¤í–‰)
      const data = await searchAutocomplete(debouncedQuery);
      setResults(data);
    };
  }, [debouncedQuery]);
```

#### 6-3. ë“œë¡­ë‹¤ìš´ì— ì‹œë§¨í‹± ê²°ê³¼ ì„¹ì…˜ ì¶”ê°€

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”  ë¹„ì˜¤ëŠ” ë‚  í˜¼ì ë³´ê¸° ì¢‹ì€ ì”ì”í•œ ì˜í™”    â”‚ â† ì…ë ¥
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ¨ AI ì¶”ì²œ ê²°ê³¼                            â”‚ â† ì‹œë§¨í‹± ê²°ê³¼ (ìƒˆë¡œ ì¶”ê°€)
â”‚  ğŸ¬ ì‡¼ìƒí¬ íƒˆì¶œ        â­ 9.1  ë“œë¼ë§ˆ      â”‚
â”‚  ğŸ¬ ì¸ìƒì€ ì•„ë¦„ë‹¤ì›Œ     â­ 8.6  ë“œë¼ë§ˆ      â”‚
â”‚  ğŸ¬ êµ¿ ìœŒ í—ŒíŒ…        â­ 8.3  ë“œë¼ë§ˆ       â”‚
â”‚  ğŸ¬ ì–´ë°”ì›ƒ íƒ€ì„        â­ 7.9  ë¡œë§¨ìŠ¤      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¬ ì˜í™”                                   â”‚ â† ê¸°ì¡´ í‚¤ì›Œë“œ ê²°ê³¼
â”‚  ...                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "ë¹„ì˜¤ëŠ” ë‚  í˜¼ì ë³´ê¸° ì¢‹ì€..." ì „ì²´ ê²€ìƒ‰     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 6-4. ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ (`/movies`)

ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì „ì²´ í˜ì´ì§€ì—ì„œë„ í‘œì‹œ. ê¸°ì¡´ `/movies?query=` ë¡œì§ì— ë¶„ê¸° ì¶”ê°€:

```typescript
// app/movies/page.tsx â€” ê¸°ì¡´ ê²€ìƒ‰ê³¼ ê³µì¡´

if (isNaturalLanguageQuery(query)) {
  // ì‹œë§¨í‹± ê²€ìƒ‰ API í˜¸ì¶œ
  const semanticResults = await fetchSemanticSearch(query, limit, ageRating);
  // ê²°ê³¼ë¥¼ ê¸°ì¡´ MovieCard ê·¸ë¦¬ë“œë¡œ ë Œë”ë§
  // ìƒë‹¨ì— "AIê°€ ì¶”ì²œí•˜ëŠ” ê²°ê³¼" ë°°ë„ˆ í‘œì‹œ
} else {
  // ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ (í˜„ì¬ ë¡œì§ ê·¸ëŒ€ë¡œ)
}
```

#### 6-5. API í•¨ìˆ˜ ì¶”ê°€

```typescript
// lib/api.ts

export interface SemanticSearchResult {
  id: number;
  title: string;
  title_ko: string | null;
  poster_path: string | null;
  release_date: string | null;
  weighted_score: number | null;
  genres: string[];
  semantic_score: number;
  relevance_score: number;
  match_reason: string;
}

export interface SemanticSearchResponse {
  query: string;
  results: SemanticSearchResult[];
  total: number;
  search_time_ms: number;
}

export async function semanticSearch(
  query: string,
  limit: number = 20,
  ageRating?: string
): Promise<SemanticSearchResponse> {
  const params = new URLSearchParams({ q: query, limit: String(limit) });
  if (ageRating) params.set("age_rating", ageRating);
  return fetchAPI(`/movies/semantic-search?${params}`);
}
```

---

## 7. ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì„¤ê³„

### `backend/scripts/generate_embeddings.py`

```python
"""
42,917í¸ ì˜í™” ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸.
Voyage AI voyage-multilingual-2 ëª¨ë¸ ì‚¬ìš©.

ì‚¬ìš©ë²•:
  cd backend
  python scripts/generate_embeddings.py [--batch-size 100] [--resume]

ì¶œë ¥:
  data/embeddings/movie_embeddings.npy    (N, 1024) float32
  data/embeddings/movie_id_index.json     {"0": movie_id, ...}
  data/embeddings/embedding_metadata.json  ë©”íƒ€ ì •ë³´
"""
import argparse
import json
import logging
import os
import sys
import time
from pathlib import Path

import httpx
import numpy as np
from sqlalchemy import create_engine, text
from sqlalchemy.orm import Session

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(message)s")
logger = logging.getLogger(__name__)

VOYAGE_API_URL = "https://api.voyageai.com/v1/embeddings"
VOYAGE_MODEL = "voyage-multilingual-2"
EMBEDDING_DIM = 1024
OUTPUT_DIR = Path(__file__).parent.parent / "data" / "embeddings"
PROGRESS_FILE = OUTPUT_DIR / "progress.json"


def build_embedding_text(row: dict) -> str:
    """ì˜í™” 1í¸ì˜ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
    parts = []

    parts.append(f"ì œëª©: {row['title_ko'] or row['title']}")
    if row.get('title') and row['title'] != row.get('title_ko'):
        parts.append(f"ì˜ì–´ ì œëª©: {row['title']}")

    if row.get('genres'):
        parts.append(f"ì¥ë¥´: {row['genres']}")

    if row.get('overview'):
        parts.append(f"ì¤„ê±°ë¦¬: {row['overview'][:500]}")

    # emotion_tags â†’ ìì—°ì–´ ë³€í™˜
    if row.get('emotion_tags'):
        emotion_labels = {
            'healing': 'íë§/ì¹˜ìœ ', 'tension': 'ê¸´ì¥/ìŠ¤ë¦´',
            'energy': 'í™œê¸°/ì—ë„ˆì§€', 'romance': 'ë¡œë§¨ìŠ¤/ê°ì„±',
            'deep': 'ê¹Šì€/ì² í•™ì ', 'fantasy': 'íŒíƒ€ì§€/ìƒìƒ',
            'light': 'ê°€ë²¼ìš´/ìœ ì¾Œ'
        }
        tags = row['emotion_tags'] if isinstance(row['emotion_tags'], dict) else json.loads(row['emotion_tags'])
        high = [emotion_labels[k] for k, v in tags.items() if isinstance(v, (int, float)) and v >= 0.5]
        if high:
            parts.append(f"ë¶„ìœ„ê¸°: {', '.join(high)}")

    # weather_scores â†’ ìì—°ì–´
    if row.get('weather_scores'):
        weather_labels = {'sunny': 'ë§‘ì€ ë‚ ', 'rainy': 'ë¹„ ì˜¤ëŠ” ë‚ ', 'cloudy': 'íë¦° ë‚ ', 'snowy': 'ëˆˆ ì˜¤ëŠ” ë‚ '}
        ws = row['weather_scores'] if isinstance(row['weather_scores'], dict) else json.loads(row['weather_scores'])
        high_w = [weather_labels[k] for k, v in ws.items() if isinstance(v, (int, float)) and v >= 0.3]
        if high_w:
            parts.append(f"ì–´ìš¸ë¦¬ëŠ” ë‚ ì”¨: {', '.join(high_w)}")

    if row.get('keywords'):
        parts.append(f"í‚¤ì›Œë“œ: {row['keywords']}")

    if row.get('director_ko'):
        parts.append(f"ê°ë…: {row['director_ko']}")

    return '\n'.join(parts)


def embed_batch(texts: list[str], api_key: str) -> list[list[float]]:
    """Voyage AI APIë¡œ ë°°ì¹˜ ì„ë² ë”© (ìµœëŒ€ 128ê°œ)"""
    with httpx.Client(timeout=60.0) as client:
        resp = client.post(
            VOYAGE_API_URL,
            json={"input": texts, "model": VOYAGE_MODEL, "input_type": "document"},
            headers={"Authorization": f"Bearer {api_key}"},
        )
        resp.raise_for_status()
        data = resp.json()
    return [item["embedding"] for item in data["data"]]


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch-size", type=int, default=100)
    parser.add_argument("--resume", action="store_true", help="ì´ì „ ì§„í–‰ ì´ì–´ì„œ")
    args = parser.parse_args()

    api_key = os.environ.get("VOYAGE_API_KEY")
    if not api_key:
        logger.error("VOYAGE_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”")
        sys.exit(1)

    db_url = os.environ.get("DATABASE_URL", "postgresql://recflix:recflix123@localhost:5432/recflix")
    engine = create_engine(db_url)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # ì˜í™” ë°ì´í„° ë¡œë“œ
    with Session(engine) as session:
        rows = session.execute(text("""
            SELECT m.id, m.title, m.title_ko, m.overview, m.director_ko,
                   m.emotion_tags::text, m.weather_scores::text, m.mbti_scores::text,
                   (SELECT string_agg(g.name, ', ') FROM movie_genres mg JOIN genres g ON g.id = mg.genre_id WHERE mg.movie_id = m.id) as genres,
                   (SELECT string_agg(k.name, ', ') FROM movie_keywords mk JOIN keywords k ON k.id = mk.keyword_id WHERE mk.movie_id = m.id) as keywords
            FROM movies m
            ORDER BY m.id
        """)).fetchall()

    columns = ['id', 'title', 'title_ko', 'overview', 'director_ko',
               'emotion_tags', 'weather_scores', 'mbti_scores', 'genres', 'keywords']
    movies = [dict(zip(columns, row)) for row in rows]

    # JSONB ë¬¸ìì—´ íŒŒì‹±
    for m in movies:
        for field in ['emotion_tags', 'weather_scores', 'mbti_scores']:
            if m[field] and isinstance(m[field], str):
                m[field] = json.loads(m[field])

    logger.info("ì´ %dí¸ ì˜í™” ë¡œë“œ", len(movies))

    # ì§„í–‰ ìƒíƒœ ë¡œë“œ (resume ëª¨ë“œ)
    start_idx = 0
    all_embeddings = []
    if args.resume and PROGRESS_FILE.exists():
        with open(PROGRESS_FILE) as f:
            progress = json.load(f)
        start_idx = progress.get("completed", 0)
        partial_path = OUTPUT_DIR / "movie_embeddings_partial.npy"
        if partial_path.exists():
            all_embeddings = np.load(str(partial_path)).tolist()
        logger.info("ì´ì „ ì§„í–‰ì—ì„œ ì¬ê°œ: %d/%d", start_idx, len(movies))

    # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
    total = len(movies)
    batch_size = args.batch_size
    t_start = time.time()

    for i in range(start_idx, total, batch_size):
        batch = movies[i:i + batch_size]
        texts = [build_embedding_text(m) for m in batch]

        try:
            embeddings = embed_batch(texts, api_key)
            all_embeddings.extend(embeddings)
        except Exception as e:
            logger.error("ë°°ì¹˜ %d ì‹¤íŒ¨: %s", i, e)
            # ì§„í–‰ ì €ì¥ í›„ ì¢…ë£Œ
            _save_progress(i, all_embeddings, movies)
            sys.exit(1)

        elapsed = time.time() - t_start
        done = i + len(batch)
        eta = (elapsed / done) * (total - done) if done > 0 else 0
        logger.info(
            "[%d/%d] %.1f%% | %.0fs elapsed | ETA %.0fs",
            done, total, done / total * 100, elapsed, eta
        )

        # 1000ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
        if done % 1000 == 0:
            _save_progress(done, all_embeddings, movies)

        # Rate limit (Voyage AI: 300 RPM)
        time.sleep(0.25)

    # ìµœì¢… ì €ì¥
    embeddings_array = np.array(all_embeddings, dtype=np.float32)
    np.save(str(OUTPUT_DIR / "movie_embeddings.npy"), embeddings_array)

    movie_id_index = {str(i): movies[i]["id"] for i in range(len(movies))}
    with open(OUTPUT_DIR / "movie_id_index.json", "w") as f:
        json.dump(movie_id_index, f)

    metadata = {
        "model": VOYAGE_MODEL,
        "dims": EMBEDDING_DIM,
        "count": len(movies),
        "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "file_size_mb": round(embeddings_array.nbytes / 1024 / 1024, 1),
    }
    with open(OUTPUT_DIR / "embedding_metadata.json", "w") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    # ì •ë¦¬
    if PROGRESS_FILE.exists():
        PROGRESS_FILE.unlink()
    partial_path = OUTPUT_DIR / "movie_embeddings_partial.npy"
    if partial_path.exists():
        partial_path.unlink()

    logger.info("ì™„ë£Œ! %dí¸, %dì°¨ì›, %.1f MB", *embeddings_array.shape, embeddings_array.nbytes / 1024 / 1024)


def _save_progress(completed: int, embeddings: list, movies: list):
    """ì¤‘ê°„ ì§„í–‰ ì €ì¥"""
    with open(PROGRESS_FILE, "w") as f:
        json.dump({"completed": completed}, f)
    if embeddings:
        partial = np.array(embeddings, dtype=np.float32)
        np.save(str(OUTPUT_DIR / "movie_embeddings_partial.npy"), partial)
    logger.info("ì§„í–‰ ì €ì¥: %d/%d", completed, len(movies))


if __name__ == "__main__":
    main()
```

### ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
cd backend

# 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export VOYAGE_API_KEY="your-voyage-api-key"

# 2. ì „ì²´ ì‹¤í–‰ (~7ë¶„, 100ê°œì”© ë°°ì¹˜, 0.25ì´ˆ ë”œë ˆì´)
python scripts/generate_embeddings.py --batch-size 100

# 3. ì¤‘ë‹¨ í›„ ì¬ê°œ
python scripts/generate_embeddings.py --batch-size 100 --resume
```

### ì˜ˆìƒ ì‹œê°„/ë¹„ìš©

| í•­ëª© | ê°’ |
|------|-----|
| ì´ ì˜í™” ìˆ˜ | 42,917í¸ |
| ë°°ì¹˜ í¬ê¸° | 100í¸ |
| ë°°ì¹˜ ìˆ˜ | ~430ê°œ |
| API í˜¸ì¶œ ê°„ê²© | 0.25ì´ˆ |
| ì˜ˆìƒ ì´ ì‹œê°„ | **~7ë¶„** (API í˜¸ì¶œ + ë”œë ˆì´) |
| ì˜ˆìƒ í† í° | ~3M (50M ë¬´ë£Œ í•œë„ ì´ë‚´) |
| ë¹„ìš© | **$0** |
| ì¶œë ¥ íŒŒì¼ í¬ê¸° | ~176MB (.npy) |

---

## 8. ì˜ˆìƒ ë¦¬ì†ŒìŠ¤

### DB ìš©ëŸ‰ ë³€í™”

| í•­ëª© | í˜„ì¬ | ì¶”ê°€ |
|------|------|------|
| Railway PostgreSQL | 145 MB | 0 MB (DBì— ë²¡í„° ë¯¸ì €ì¥) |
| .npy íŒŒì¼ (Railway ë³¼ë¥¨ or ë°°í¬ ì‹œ í¬í•¨) | - | ~176 MB |
| movie_id_index.json | - | ~0.5 MB |

### ì„œë²„ ë©”ëª¨ë¦¬ ë³€í™”

| í•­ëª© | í˜„ì¬ | ì¶”ê°€ | í•©ê³„ |
|------|------|------|------|
| FastAPI + SQLAlchemy + Redis | ~200-300 MB | - | - |
| ì„ë² ë”© í–‰ë ¬ (42,917 Ã— 1,024 Ã— 4B) | - | ~176 MB | - |
| **ì´ ì˜ˆìƒ** | ~300 MB | ~176 MB | **~476 MB** |

Railway Hobby í”Œëœ 8GB RAM ê¸°ì¤€ ì¶©ë¶„. ë‹¨, .npy íŒŒì¼ì€ Railway ë³¼ë¥¨ ë˜ëŠ” ë°°í¬ ì•„í‹°íŒ©íŠ¸ì— í¬í•¨ í•„ìš”.

### ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ ì˜ˆìƒ

| ë‹¨ê³„ | ì‹œê°„ |
|------|------|
| Redis ìºì‹œ íˆíŠ¸ ì‹œ | ~1-5ms |
| Voyage API ì¿¼ë¦¬ ì„ë² ë”© | ~100-200ms |
| NumPy ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (42K Ã— 1024) | ~10-20ms |
| DB í›„ë³´ ì¡°íšŒ (100í¸) | ~20-50ms |
| í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ | ~5-10ms |
| **ì´ (ìºì‹œ ë¯¸ìŠ¤)** | **~150-300ms** |
| **ì´ (ì„ë² ë”© ìºì‹œ íˆíŠ¸)** | **~40-80ms** |

---

## 9. êµ¬í˜„ ê³„íš (Phase 33)

### ë‹¨ê³„ë³„ ì‹¤í–‰ ìˆœì„œ

| ìˆœì„œ | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ |
|------|------|----------|
| 1 | Voyage AI ê³„ì • ìƒì„± + API í‚¤ ë°œê¸‰ | 5ë¶„ |
| 2 | `backend/app/services/embedding.py` ì‘ì„± (Voyage AI í´ë¼ì´ì–¸íŠ¸) | 20ë¶„ |
| 3 | `backend/scripts/generate_embeddings.py` ì‘ì„± + ë¡œì»¬ ì‹¤í–‰ | 30ë¶„ |
| 4 | `backend/app/api/v1/semantic_search.py` ì‘ì„± (ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ) | 40ë¶„ |
| 5 | `backend/app/main.py` â€” lifespanì— ì„ë² ë”© ë¡œë“œ ì¶”ê°€ | 10ë¶„ |
| 6 | movies.pyì— `/movies/semantic-search` ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ | 30ë¶„ |
| 7 | `frontend/lib/api.ts` â€” semanticSearch API í•¨ìˆ˜ ì¶”ê°€ | 10ë¶„ |
| 8 | `frontend/lib/searchUtils.ts` â€” ìì—°ì–´ ê°ì§€ ìœ í‹¸ | 10ë¶„ |
| 9 | SearchAutocomplete ì‹œë§¨í‹± ê²°ê³¼ ì„¹ì…˜ ì¶”ê°€ | 40ë¶„ |
| 10 | ì˜í™” ê²€ìƒ‰ í˜ì´ì§€ ì‹œë§¨í‹± ëª¨ë“œ ë¶„ê¸° | 30ë¶„ |
| 11 | config.pyì— `VOYAGE_API_KEY` ì¶”ê°€ | 5ë¶„ |
| 12 | requirements.txt ì—…ë°ì´íŠ¸ (voyageai ë˜ëŠ” httpxë§Œ ì‚¬ìš©) | 5ë¶„ |
| 13 | í”„ë¡œë•ì…˜ ë°°í¬ (Railwayì— .npy í¬í•¨ + Vercel) | 20ë¶„ |

### ìƒˆë¡œ ì¶”ê°€/ë³€ê²½ë˜ëŠ” íŒŒì¼

```
ìƒˆë¡œ ìƒì„±:
  backend/app/services/embedding.py          # Voyage AI í´ë¼ì´ì–¸íŠ¸
  backend/app/api/v1/semantic_search.py      # ë²¡í„° ê²€ìƒ‰ ëª¨ë“ˆ
  backend/scripts/generate_embeddings.py     # ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸
  backend/data/embeddings/                   # ë²¡í„° ë°ì´í„° ë””ë ‰í† ë¦¬
  frontend/lib/searchUtils.ts                # ìì—°ì–´ ê°ì§€ ìœ í‹¸

ìˆ˜ì •:
  backend/app/core/config.py                 # VOYAGE_API_KEY ì¶”ê°€
  backend/app/api/v1/movies.py               # ì‹œë§¨í‹± ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
  backend/app/api/v1/router.py               # semantic_search ë¼ìš°í„° ë“±ë¡
  backend/app/main.py                        # lifespanì— ì„ë² ë”© ë¡œë“œ
  backend/requirements.txt                   # (httpxëŠ” ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ë³€ê²½ ë¶ˆí•„ìš”)
  frontend/lib/api.ts                        # semanticSearch í•¨ìˆ˜ ì¶”ê°€
  frontend/components/search/SearchAutocomplete.tsx  # ì‹œë§¨í‹± ê²°ê³¼ ì„¹ì…˜
  frontend/app/movies/page.tsx               # ì‹œë§¨í‹± ê²€ìƒ‰ ëª¨ë“œ ë¶„ê¸°
```

### í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

```bash
# backend/.env (ë¡œì»¬)
VOYAGE_API_KEY=your-voyage-api-key

# Railway (í”„ë¡œë•ì…˜)
VOYAGE_API_KEY=your-voyage-api-key
```

---

## 10. ë¦¬ìŠ¤í¬ ë° ëŒ€ì•ˆ

| ë¦¬ìŠ¤í¬ | ì˜í–¥ | ëŒ€ì•ˆ |
|--------|------|------|
| Voyage AI ë¬´ë£Œ í•œë„ ì†Œì§„ | ì¿¼ë¦¬ ì„ë² ë”© ë¶ˆê°€ | Redis ìºì‹œë¡œ ë™ì¼ ì¿¼ë¦¬ ì¬ì‚¬ìš© ìµœì†Œí™” / OpenAIë¡œ í´ë°± |
| Railwayì—ì„œ 176MB .npy ë¡œë“œ ì‹œê°„ | ì„œë²„ ì‹œì‘ ëŠë ¤ì§ (~5ì´ˆ) | lazy loading ë˜ëŠ” mmap ëª¨ë“œ (`np.load(mmap_mode='r')`) |
| í•œêµ­ì–´ ê²€ìƒ‰ í’ˆì§ˆ ë¶€ì¡± | ê´€ë ¨ ì—†ëŠ” ê²°ê³¼ ë°˜í™˜ | ì„ë² ë”© í…ìŠ¤íŠ¸ í…œí”Œë¦¿ íŠœë‹ / ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì¶”ê°€ |
| Voyage AI ì„œë¹„ìŠ¤ ì¥ì•  | ì‹œë§¨í‹± ê²€ìƒ‰ ë¶ˆê°€ | ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ graceful fallback |

### Graceful Degradation

```python
# ì‹œë§¨í‹± ê²€ìƒ‰ ë¶ˆê°€ ì‹œ ê¸°ì¡´ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
@router.get("/semantic-search")
async def semantic_search(q: str, ...):
    if not is_semantic_search_available():
        # ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        return await keyword_search_fallback(q, limit, age_rating, db)

    embedding = await get_query_embedding(q)
    if embedding is None:
        # ì„ë² ë”© ì‹¤íŒ¨ ì‹œì—ë„ í‚¤ì›Œë“œ í´ë°±
        return await keyword_search_fallback(q, limit, age_rating, db)

    # ì •ìƒ ì‹œë§¨í‹± ê²€ìƒ‰ ì§„í–‰
    ...
```
